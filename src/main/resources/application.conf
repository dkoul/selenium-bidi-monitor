seleniumiq {
  # LLM Configuration
  llm {
    # Supported providers: openai, anthropic, ollama
    provider = "ollama"
    
    # API Configuration (for cloud providers)
    api {
      base-url = "https://api.openai.com/v1"
      key = ${?OPENAI_API_KEY}
      model = "gpt-4"
      timeout = 30s
      max-retries = 3
    }
    
    # Ollama Configuration (local AI models)
    ollama {
      base-url = "http://localhost:11434"
      model = "mistral:latest"  # Available models: mistral:latest, llama3:latest, codellama:latest
    }
    
    # Azure OpenAI Configuration (alternative)
    azure {
      endpoint = ${?AZURE_OPENAI_ENDPOINT}
      key = ${?AZURE_OPENAI_KEY}
      deployment = "gpt-4"
      api-version = "2023-12-01-preview"
    }
  }
  
  # Monitoring Configuration
  monitoring {
    # Enable/disable monitoring
    enabled = true
    
    # Event capture settings
    events {
      console-logs = true
      network-requests = true
      performance-metrics = true
      dom-mutations = false  # Can be resource intensive
      javascript-exceptions = true
      security-violations = true
    }
    
    # Filtering and sampling
    filters {
      # Minimum log level to capture (DEBUG, INFO, WARN, ERROR)
      min-log-level = "WARN"
      
      # Network request filtering
      network {
        # Only capture failed requests (4xx, 5xx)
        failed-requests-only = false
        # Exclude specific domains
        excluded-domains = ["analytics.google.com", "doubleclick.net"]
        # Include only specific content types
        included-content-types = ["application/json", "text/html", "application/javascript"]
      }
      
      # Performance thresholds
      performance {
        slow-request-threshold = 5000  # milliseconds
        memory-usage-threshold = 100   # MB
        cpu-usage-threshold = 80       # percentage
      }
    }
    
    # Analysis and suggestions
    analysis {
      # Batch size for LLM analysis
      batch-size = 10
      
      # Analysis interval
      analysis-interval = 30s
      
      # Enable real-time suggestions
      real-time-suggestions = true
      
      # Suggestion categories
      categories = [
        "performance-optimization",
        "error-resolution",
        "test-stability",
        "security-improvements",
        "best-practices"
      ]
    }
    
    # Output configuration
    output {
      # Output formats: json, html, markdown
      format = "json"
      
      # Output destinations
      destinations = [
        {
          type = "file"
          path = "./monitoring-reports"
          filename-pattern = "selenium-monitor-{timestamp}.json"
        },
        {
          type = "console"
          level = "INFO"
        }
      ]
      
      # Report generation
      reports {
        generate-summary = true
        include-suggestions = true
        include-raw-events = false
        max-events-per-report = 1000
      }
    }
  }
  
  # Browser-specific settings
  browsers {
    chrome {
      enable-bidi = true
      additional-args = ["--enable-logging", "--v=1"]
    }
    
    firefox {
      enable-bidi = true
      log-level = "INFO"
    }
    
    edge {
      enable-bidi = true
    }
  }
} 